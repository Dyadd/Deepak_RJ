<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Deepak RJ">
<meta name="dcterms.date" content="2024-12-29">
<meta name="description" content="What aviation can teach us about medical AI">

<title>Medical AI: Lessons on Good Human-Computer Interaction – Deepak RJ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0626ff4d7a71b55c8707dcae1d04a9b6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-70fcee90e424b40fbce301364aa4825f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Deepak RJ</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/mAI_HCI_detailed/index.html">Recent Posts</a></li><li class="breadcrumb-item"><a href="../../posts/mAI_HCI_detailed/index.html">Medical AI: Lessons on Good Human-Computer Interaction</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/mAI_HCI_detailed/index.html">Recent Posts</a></li><li class="breadcrumb-item"><a href="../../posts/mAI_HCI_detailed/index.html">Medical AI: Lessons on Good Human-Computer Interaction</a></li></ol></nav>
      <h1 class="title">Medical AI: Lessons on Good Human-Computer Interaction</h1>
                  <div>
        <div class="description">
          What aviation can teach us about medical AI
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">HCI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Deepak RJ </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 29, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Recent Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/mAI_HCI_detailed/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Medical AI: Lessons on Good Human-Computer Interaction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/medical-student-writing/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Why Medical Students Should Blog</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/What_Medicine_needs_to_get_right_about_AI/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What Medicine needs to get right about AI</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-introduction" id="toc-sec-introduction" class="nav-link active" data-scroll-target="#sec-introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#the-core-challenge" id="toc-the-core-challenge" class="nav-link" data-scroll-target="#the-core-challenge"><span class="header-section-number">2</span> The Core Challenge</a>
  <ul class="collapse">
  <li><a href="#the-spectrum-of-ai-integration" id="toc-the-spectrum-of-ai-integration" class="nav-link" data-scroll-target="#the-spectrum-of-ai-integration"><span class="header-section-number">2.1</span> The Spectrum of AI Integration</a></li>
  <li><a href="#a-framework-for-integration-situation-awareness" id="toc-a-framework-for-integration-situation-awareness" class="nav-link" data-scroll-target="#a-framework-for-integration-situation-awareness"><span class="header-section-number">2.2</span> A Framework for Integration: Situation Awareness</a>
  <ul class="collapse">
  <li><a href="#understanding-sa-through-a-medical-example" id="toc-understanding-sa-through-a-medical-example" class="nav-link" data-scroll-target="#understanding-sa-through-a-medical-example"><span class="header-section-number">2.2.1</span> Understanding SA Through a Medical Example</a></li>
  <li><a href="#moving-beyond-individual-sa-a-complex-systems-perspective" id="toc-moving-beyond-individual-sa-a-complex-systems-perspective" class="nav-link" data-scroll-target="#moving-beyond-individual-sa-a-complex-systems-perspective"><span class="header-section-number">2.2.2</span> Moving Beyond Individual SA: A Complex Systems Perspective</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#the-medical-context-three-key-tensions" id="toc-the-medical-context-three-key-tensions" class="nav-link" data-scroll-target="#the-medical-context-three-key-tensions"><span class="header-section-number">3</span> The Medical Context: Three Key Tensions</a>
  <ul class="collapse">
  <li><a href="#automation-vs.-human-agency" id="toc-automation-vs.-human-agency" class="nav-link" data-scroll-target="#automation-vs.-human-agency"><span class="header-section-number">3.1</span> Automation vs.&nbsp;Human Agency</a>
  <ul class="collapse">
  <li><a href="#the-automation-paradox-in-medicine" id="toc-the-automation-paradox-in-medicine" class="nav-link" data-scroll-target="#the-automation-paradox-in-medicine"><span class="header-section-number">3.1.1</span> The Automation Paradox in Medicine</a></li>
  <li><a href="#situation-awareness" id="toc-situation-awareness" class="nav-link" data-scroll-target="#situation-awareness"><span class="header-section-number">3.1.2</span> Situation Awareness</a></li>
  </ul></li>
  <li><a href="#system-uncertainty-vs.-user-confidence" id="toc-system-uncertainty-vs.-user-confidence" class="nav-link" data-scroll-target="#system-uncertainty-vs.-user-confidence"><span class="header-section-number">3.2</span> System Uncertainty vs.&nbsp;User Confidence</a>
  <ul class="collapse">
  <li><a href="#clinical-scenario" id="toc-clinical-scenario" class="nav-link" data-scroll-target="#clinical-scenario"><span class="header-section-number">3.2.1</span> Clinical Scenario</a></li>
  <li><a href="#situation-awareness-1" id="toc-situation-awareness-1" class="nav-link" data-scroll-target="#situation-awareness-1"><span class="header-section-number">3.2.2</span> Situation Awareness</a></li>
  </ul></li>
  <li><a href="#system-complexity-vs.-perceived-complexity" id="toc-system-complexity-vs.-perceived-complexity" class="nav-link" data-scroll-target="#system-complexity-vs.-perceived-complexity"><span class="header-section-number">3.3</span> System Complexity vs.&nbsp;Perceived Complexity</a>
  <ul class="collapse">
  <li><a href="#situation-awareness-2" id="toc-situation-awareness-2" class="nav-link" data-scroll-target="#situation-awareness-2"><span class="header-section-number">3.3.1</span> Situation Awareness</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-takeaways" id="toc-sec-takeaways" class="nav-link" data-scroll-target="#sec-takeaways"><span class="header-section-number">4</span> Key Takeaways</a></li>
  <li><a href="#sec-conclusion" id="toc-sec-conclusion" class="nav-link" data-scroll-target="#sec-conclusion"><span class="header-section-number">5</span> Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/dyadd/Deepak_RJ/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="sec-introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>We can draw from a rich literature of human-computer interaction (HCI), applied automation in aviation and now emerging human-centered AI (HCAI) to think about medical AI. Many new problems we’re running into now are older problems in disguise. In this article, we’ll draw on premises from the <a href="../../posts/What_Medicine_needs_to_get_right_about_AI/index.html#the-implementation-challenge">key implementation challenges</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Context
</div>
</div>
<div class="callout-body-container callout-body">
<p>This essay builds on <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2093863">foundational research</a> from Jiang et al and expands their framework with practical medical applications.</p>
</div>
</div>
</section>
<section id="the-core-challenge" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> The Core Challenge</h1>
<p>The practical implementation of AI in professional work faces a critical challenge: how to effectively integrate automated systems while preserving human expertise and judgment. While current literature provides <a href="https://www.jmir.org/2022/10/e40238/">theoretical frameworks</a>, we need concrete strategies for real-world application.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Insight
</div>
</div>
<div class="callout-body-container callout-body">
<p>Knowledge work automation represents a <a href="https://arxiv.org/abs/2312.05481">fundamental shift</a> - AI’s embedded world models make human knowledge scalable beyond the previous limitation of human time.</p>
</div>
</div>
<section id="the-spectrum-of-ai-integration" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-spectrum-of-ai-integration"><span class="header-section-number">2.1</span> The Spectrum of AI Integration</h2>
<p>AI tools exist on a spectrum from autonomous to assistive:</p>
<ol type="1">
<li>Autonomous systems like <a href="https://www.salesforce.com/au/agentforce/">Salesforce’s Agentforce</a> can independently handle tasks like prospect outreach</li>
<li>Copilot systems like <a href="https://github.com/features/copilot">GitHub Copilot</a> augment human work by suggesting improvements</li>
<li>Hybrid approaches combine both, varying by sector and risk profile</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most implementations will likely fall somewhere between fully autonomous and purely assistive, adapting based on the specific context and risk level of the domain.</p>
<p>For example, a medical copilot might autonomously gather drug interaction data while requiring human oversight for final dosing decisions.</p>
</div>
</div>
<p>For effective integration, well-trained staff is critical. Jeremy Howard’s new law firm, <a href="https://www.legaltech-talk.com/jeremy-howards-new-ai-law-firm-virgil-aims-to-serve-the-startup-industry/">Virgil</a>, aims for bottom-up integration of AI with staff education and AI integration from the get-go.</p>
<p>Similar to law, medicine is a field where risk is crucially minimised. Patient safety must be at the forefront. <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2093863">Jiang et al</a> have identified <strong>3 key tensions</strong> we need to solve before we can integrate AI. We’ll largely summarise their fantastic paper while applying it to medicine - please read their full paper and cite them if used.</p>
</section>
<section id="a-framework-for-integration-situation-awareness" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="a-framework-for-integration-situation-awareness"><span class="header-section-number">2.2</span> A Framework for Integration: Situation Awareness</h2>
<p>Before examining the tensions in human-AI interaction, we need to understand Situation Awareness (SA). While SA originated in aviation, it offers valuable insights into how humans and AI systems interact.</p>
<p>At its core, SA describes how humans gather and process information to solve problems. Think of it as the foundation that supports decision-making - separate from the decisions themselves.</p>
<p>Even skilled decision-makers can make mistakes if their SA is incomplete or incorrect. Similarly, someone with excellent awareness might still make wrong choices due to gaps in knowledge or training.</p>
<p>SA unfolds in three distinct levels:</p>
<ol type="1">
<li><strong>Perception</strong>: Noticing key elements in your environment within a specific time and space</li>
<li><strong>Comprehension</strong>: Making sense of what these elements mean</li>
<li><strong>Projection</strong>: Anticipating how the situation might develop</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2093863"><img src="situation awareness.jpg" class="img-fluid figure-img" alt="Situation Awareness"></a></p>
<figcaption>Situation Awareness</figcaption>
</figure>
</div>
<section id="understanding-sa-through-a-medical-example" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="understanding-sa-through-a-medical-example"><span class="header-section-number">2.2.1</span> Understanding SA Through a Medical Example</h3>
<p>Let’s explore how SA works in a hospital setting:</p>
<section id="level-1-perception" class="level4" data-number="2.2.1.1">
<h4 data-number="2.2.1.1" class="anchored" data-anchor-id="level-1-perception"><span class="header-section-number">2.2.1.1</span> Level 1: Perception</h4>
<p>Picture yourself on a ward round. You’re taking in everything around the patient - their appearance, vital signs, recent test results, and examination changes. You notice the electronic medical record (EMR) displaying key data, while also being aware of the broader environment: available nursing staff, family presence, and the treating team. This initial stage builds your mental model of the current situation.</p>
</section>
<section id="level-2-comprehension" class="level4" data-number="2.2.1.2">
<h4 data-number="2.2.1.2" class="anchored" data-anchor-id="level-2-comprehension"><span class="header-section-number">2.2.1.2</span> Level 2: Comprehension</h4>
<p>Now comes synthesis. A doctor combines all these elements into meaningful patterns. For instance, seeing low blood pressure alongside cool extremities and reduced urine output forms a clear picture of poor tissue perfusion - a gestalt that’s more meaningful than any single observation.</p>
</section>
<section id="level-3-projection-and-planning" class="level4" data-number="2.2.1.3">
<h4 data-number="2.2.1.3" class="anchored" data-anchor-id="level-3-projection-and-planning"><span class="header-section-number">2.2.1.3</span> Level 3: Projection and Planning</h4>
<p>This is where experience and implicit learning shine. Based on the patterns recognized, a clinician can anticipate likely developments. They might predict that a patient with worsening respiratory symptoms and dropping oxygen levels will need intensive care soon, allowing them to start preparations early.</p>
</section>
</section>
<section id="moving-beyond-individual-sa-a-complex-systems-perspective" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="moving-beyond-individual-sa-a-complex-systems-perspective"><span class="header-section-number">2.2.2</span> Moving Beyond Individual SA: A Complex Systems Perspective</h3>
<p>Traditional SA focuses on individual decision-makers, but modern healthcare demands a broader view.</p>
<p>The <em>Distributed Situation Awareness</em> model recognizes that cognition is shared across a network of human agents, technological tools, and now AI systems. This creates a complex environment where the whole system’s capabilities exceed what any individual could achieve alone.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2093863"><img src="distributed situation awareness.jpg" class="img-fluid figure-img" alt="Distributed Situation Awareness"></a></p>
<figcaption>Distributed Situation Awareness</figcaption>
</figure>
</div>
<p>Take a modern aircraft landing. The pilot doesn’t manually calculate wind speeds, drag coefficients, or optimal flap positions. Instead, they interact with a carefully designed system that:</p>
<ul>
<li>Processes thousands of data points about weather, aircraft weight, speed, and trajectory</li>
<li>Automatically adjusts micro-controls like precise flap angles</li>
<li>Presents only the essential information the pilot needs for decision-making</li>
<li>Alerts the pilot when specific actions are needed</li>
</ul>
<p>The pilot achieves “perfect” task awareness <strong>not by knowing every calculation</strong>, but by <strong>understanding the right information at the right time</strong>. They trust the system to handle complex calculations while focusing on higher-level decisions about the landing approach.</p>
<p>This is the concept of “transactional memory”. Information is distributed across people and technology. Healthcare has always relied on distributed knowledge:</p>
<section id="traditional-distribution" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="traditional-distribution"><span class="header-section-number">2.2.2.1</span> Traditional Distribution</h4>
<ul>
<li>Clinical guidelines synthesize evidence and expertise across the field</li>
<li>Subspecialists develop deep knowledge in narrow domains</li>
<li>Regular updates and revisions reflect new evidence</li>
<li>Teams combine different expertise for complex cases</li>
</ul>
</section>
<section id="ai-enhanced-knowledge-systems" class="level4" data-number="2.2.2.2">
<h4 data-number="2.2.2.2" class="anchored" data-anchor-id="ai-enhanced-knowledge-systems"><span class="header-section-number">2.2.2.2</span> AI-Enhanced Knowledge Systems</h4>
<p>The introduction of AI creates new possibilities for knowledge work:</p>
<ol type="1">
<li>Dynamic Knowledge Retrieval</li>
</ol>
<ul>
<li>AI can instantly access and synthesize vast medical literature</li>
<li>Real-time updates as new evidence emerges</li>
<li>Contextual retrieval based on specific patient scenarios</li>
</ul>
<ol start="2" type="1">
<li>Knowledge Iteration</li>
</ol>
<ul>
<li>AI systems can test hypotheses across large datasets</li>
<li>Rapid identification of patterns and correlations</li>
<li>Continuous learning from clinical outcomes</li>
</ul>
<ol start="3" type="1">
<li>Knowledge Testing</li>
</ol>
<ul>
<li>Simulation of treatment approaches</li>
<li>Validation of guidelines across diverse populations</li>
<li>Early identification of potential risks or limitations</li>
</ul>
<ol start="4" type="1">
<li>Knowledge Refinement</li>
</ol>
<ul>
<li>Integration of multiple knowledge sources</li>
<li>Adaptation to local contexts and populations</li>
<li>Identification of gaps in current understanding</li>
</ul>
<p>A completely new balance emerges from AI on distributed situation awareness. AI capabilities can complement human expertise in ways previously impossible.</p>
</section>
</section>
</section>
</section>
<section id="the-medical-context-three-key-tensions" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> The Medical Context: Three Key Tensions</h1>
<p>Medicine provides a crucial case study in AI integration, where patient safety is paramount. Drawing from <a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2093863">Jiang et al.’s work</a>, three fundamental tensions emerge:</p>
<section id="automation-vs.-human-agency" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="automation-vs.-human-agency"><span class="header-section-number">3.1</span> Automation vs.&nbsp;Human Agency</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Takeaway
</div>
</div>
<div class="callout-body-container callout-body">
<p>You need the right ‘window’ into the assistant AI, with the right information at the right time for a highly trained clinician.</p>
<p>This enables effective human-AI collaboration that doesn’t restrict human agency &amp; correctly uses AI.</p>
</div>
</div>
<section id="the-automation-paradox-in-medicine" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-automation-paradox-in-medicine"><span class="header-section-number">3.1.1</span> The Automation Paradox in Medicine</h3>
<p>Consider a future where AI manages:</p>
<ul>
<li>Interpreting data-intensive multi-omic analyses</li>
<li>Pharmacogenomic modeling</li>
<li>Drug dosing for personalized medicine</li>
</ul>
<p>Better investigation can help us better characterise disease but this likely requires significant data analysis. This data analysis may mean greater diagnostic accuracy and treatment precision, leading to improved patient outcomes. However, the tension would arise when the intelligent system makes clinical recommendations based upon complex biomarker patterns that are opaque to the human physician and at a level of molecular detail that the human physician cannot fully process, leading to a mismatch in shared understanding between humans and AI. This negates the benefit gained from AI-powered data analysis.</p>
<p>Consider even far sooner future where AI looks through the EMR and flags where treatment <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC4818118/">deviates from guidelines</a>: The clinician needs to be trained to understand deeply how these AI-driven systems work and also how/when these systems fail. Automation bias refers to the deskilling of staff, shown to disproportionally affect <a href="https://doi.org/10.1016/j.jelectrocard.2018.08.007">non-specialist doctors in ECG interpretation</a>. This means users need to be substantial domain experts in both medicine &amp; applied AI to safely stay in the loop.</p>
</section>
<section id="situation-awareness" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="situation-awareness"><span class="header-section-number">3.1.2</span> Situation Awareness</h3>
<p>To improve human agency, SA is applied as such:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Current Status (Level 1 SA - Perception)</th>
<th>Reasoning Process (Level 2 SA - Comprehension)</th>
<th>Future Projections (Level 3 SA - Projection)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ul>
<li>Shows the AI’s goals and current actions</li>
<li>Displays environmental data and performance metrics</li>
<li>Helps users see what the AI sees</li>
</ul></td>
<td><ul>
<li>Explains why the AI makes specific choices</li>
<li>Shows constraints affecting AI decisions</li>
<li>Helps users understand AI behavior</li>
</ul></td>
<td><ul>
<li><p>Predicts next steps</p></li>
<li><p>Helps users see what the reasoning leads to</p></li>
</ul></td>
</tr>
</tbody>
</table>
<section id="clinical-application-dermatology-ai-assistant" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="clinical-application-dermatology-ai-assistant"><span class="header-section-number">3.1.2.1</span> Clinical Application: Dermatology AI Assistant</h4>
<p>To illustrate these principles, consider an AI system supporting skin cancer screening:</p>
<p>A dermatologist examines a patient with multiple atypical moles. The AI flags one as high-risk melanoma (89% confidence), though it doesn’t match typical patterns. Here are important considerations to retain clinician agency &amp; augment performance.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 31%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Level 1: Perception</th>
<th>Level 2: Comprehension</th>
<th>Level 3: Projection</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ul>
<li><p>Clear images of the lesion</p></li>
<li><p>Enhanced visualizations</p></li>
<li><p>Feature detection results</p></li>
</ul></td>
<td><ul>
<li><p>Heat maps of concerning areas</p></li>
<li><p>Breakdown of each concerning feature</p></li>
<li><p>Similar cases from training data</p></li>
<li><p>Notes on atypical features</p></li>
</ul></td>
<td><ul>
<li><p>Statistical outcome predictions</p></li>
<li><p>Recommended monitoring schedule</p></li>
<li><p>Growth projections</p></li>
<li><p>Alternative diagnoses to consider given biopsy results</p></li>
</ul></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Benefits for Physician Autonomy
</div>
</div>
<div class="callout-body-container callout-body">
<p>This approach maintains physician control &amp; creates effective AI-physician collaboration by critically:</p>
<ul>
<li><p>Making AI decisions transparent <strong>in the way the physician thinks</strong> <em>(AI SA supports physician SA)</em></p></li>
<li><p>Allowing investigation of AI recommendations <strong>because fits into physician SA</strong> <em>(AI SA supports physician SA)</em></p></li>
</ul>
</div>
</div>
</section>
</section>
</section>
<section id="system-uncertainty-vs.-user-confidence" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="system-uncertainty-vs.-user-confidence"><span class="header-section-number">3.2</span> System Uncertainty vs.&nbsp;User Confidence</h2>
<p>Consider an AI clinical decision support system. It uses all of the available multimodal data it has (e.g.&nbsp;all EMR data, all imaging, all relevant guidelines) and suggests next actions in a clinical workflow.</p>
<p>Without intelligently handling the known unknowns and the unknown unknowns, the system risks communicating itself with overconfidence, harming physician autonomy and trust.</p>
<section id="clinical-scenario" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="clinical-scenario"><span class="header-section-number">3.2.1</span> Clinical Scenario</h3>
<p>A 58-year-old patient presents to the Emergency Department with abdominal pain. The hospital’s AI system analyzes available data:</p>
<p>EMR review:</p>
<ul>
<li><p>Well-controlled diabetes</p></li>
<li><p>Recent normal colonoscopy</p></li>
<li><p>Stable vital signs</p></li>
<li><p>CT scan suggesting appendicitis</p></li>
<li><p>Mildly elevated white blood cell count</p></li>
</ul>
<p>Based on these findings and clinical guidelines, the AI system confidently recommends an immediate surgical consultation for an appendicectomy/appendectomy.</p>
<p>However, critical information remains outside the AI’s analysis:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 42%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th>Known gaps</th>
<th>Potential unknowns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ul>
<li><p>Recent travel history (not in EMR)</p></li>
<li><p>Current medication list (undocumented)</p></li>
<li><p>Precise onset timing of pain</p></li>
</ul></td>
<td><ul>
<li><p>Anatomical variations</p></li>
<li><p>Unusual pathogens</p></li>
<li><p>Undocumented family history of inflammatory conditions</p></li>
</ul></td>
</tr>
</tbody>
</table>
<p>The treating physician, drawing on years of clinical experience and subtle patient cues, senses something atypical about the presentation. Rather than proceeding directly to surgery, they pursue additional workup - ultimately discovering a rare parasitic infection contracted during the patient’s recent international travel, which had mimicked appendicitis.</p>
<p>This scenario demonstrates how an AI system that doesn’t explicitly acknowledge uncertainty could prematurely narrow the diagnostic consideration and potentially override valuable physician intuition and clinical judgment. A better system would present its recommendations with <strong>appropriate caveats and confidence levels</strong>, explicitly noting what information is <strong>missing or uncertain</strong>, better supporting physician decision-making.</p>
</section>
<section id="situation-awareness-1" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="situation-awareness-1"><span class="header-section-number">3.2.2</span> Situation Awareness</h3>
<p>Applying SA in this scenario means expressing the uncertainty of the AI system. The extent to which displaying these uncertainty metrics actually improves physician confidence and decision-making remains unclear - would overall outcomes improve if it showed 65% confidence with clear knowledge gaps, versus 85% confidence without acknowledging uncertainties? Does breaking down uncertainty into specific components help or hinder clinical workflow?</p>
<p>An SA-oriented design would structure uncertainty representation across three cognitive levels, helping physicians build a complete mental model of the situation:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 31%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Level 1: Perception</th>
<th>Level 2: Comprehension</th>
<th>Level 3: Projection</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ul>
<li><p>Shows what data is missing from the AI’s patient model - including physical exam nuances, patient affect, and symptom progression</p></li>
<li><p>Displays standard data like CT and lab results alongside clear indicators of what information isn’t captured</p></li>
<li><p>Makes gaps in the AI’s understanding explicit to help doctors put recommendations in context</p></li>
</ul></td>
<td><ul>
<li><p>Shows how different uncertainties combine to affect the AI’s confidence levels</p></li>
<li><p>Demonstrates relationships between factors (e.g., how unusual pain patterns + incomplete medication history + unclear symptom timing affect diagnostic confidence)</p></li>
<li><p>Reveals the AI’s reasoning process rather than just showing isolated confidence scores</p></li>
</ul></td>
<td><ul>
<li><p>Enables physicians to actively explore different diagnostic and treatment pathways while considering uncertainties</p></li>
<li><p>Allows you to drill into specific concerns (like possible travel-related infections), update the AI’s reasoning to determine change in projection (“If this patient did travel to India for 3 months, what are you differentials now?”)</p></li>
</ul></td>
</tr>
</tbody>
</table>
<p>This approach recognizes that managing clinical uncertainty isn’t passive - physicians need to actively engage with the information, controlling how they view and interpret different uncertainty elements based on their expertise and the specific patient context. By organising uncertainty information around clinical goals and supporting both detailed symptom analysis and broader diagnostic consideration, the system helps physicians develop their own situation assessment while maintaining appropriate confidence in both the AI’s suggestions and their own clinical judgment.</p>
<p>This design philosophy helps harmonize the tension between the AI’s inherent limitations and the physician’s need for confident decision-making, without compromising the crucial role of clinical expertise and intuition.</p>
</section>
</section>
<section id="system-complexity-vs.-perceived-complexity" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="system-complexity-vs.-perceived-complexity"><span class="header-section-number">3.3</span> System Complexity vs.&nbsp;Perceived Complexity</h2>
<p>This final tension underlies the entire human-AI interaction. Modern clinical AI systems are inherently complex, integrating multiple components and data sources. In our ED scenario, the system simultaneously processes:</p>
<ul>
<li><p>Structured EMR data (labs, vitals, medications)</p></li>
<li><p>Unstructured clinical notes</p></li>
<li><p>Imaging data through computer vision algorithms</p></li>
<li><p>Clinical guidelines and medical literature</p></li>
<li><p>Population-level statistics and outcomes data</p></li>
</ul>
<p>As the systems grows in complexity, choosing what to show to clinicians grows in importance.</p>
<p>Like how micro-calculations of flap adjustment doesn’t need to be visible to the pilot, physicians need a balanced view, enough to maintain trust while preventing information overload. The operational complexity can remain manageable with a moderate perceived complexity, despite significant objective complexity.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Complexity Definitions
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>Objective Complexity:</strong> objectively what the system is doing - considering guidelines, statistics, scan results, notes, etc.</p></li>
<li><p><strong>Perceived Complexity:</strong> the complexity perceived by the clinician:</p>
<ul>
<li><p>When we distribute knowledge like trusting the pathologist to accurately read biopsy slides or the MRI machine to function properly, the perceived complexity is reduced to a simple pathology report or conversation with the radiologist.</p></li>
<li><p>We aim for reducing the perceived complexity in interdisciplinary conversations to minimise cognitive workload and maximise productivity.</p></li>
</ul></li>
<li><p><strong>Operational Complexity:</strong> refers to the task’s complexity - diagnosing appendicitis may require:</p>
<ul>
<li><p>Multiple interdependent decisions (ordering tests, interpreting results, choosing treatments)</p></li>
<li><p>Similar presenting symptoms potentially leading to different diagnoses &amp; various decision paths that could lead to the same diagnosis</p></li>
<li><p>Need to constantly re-evaluate as new information arrives</p></li>
</ul></li>
</ul>
</div>
</div>
<p>This is the hardest balance to strike. Perceived complexity changes vastly based on interface design decisions:</p>
<ul>
<li><p>Showing comprehensive evidence supporting the AI’s appendicitis recommendation versus overwhelming the physician with data</p></li>
<li><p>Balancing immediate diagnostic suggestions with the need to communicate uncertainty</p></li>
<li><p>Determining how much of the AI’s reasoning process to expose</p></li>
<li><p>Adapting information density based on case urgency and complexity</p></li>
</ul>
<section id="situation-awareness-2" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="situation-awareness-2"><span class="header-section-number">3.3.1</span> Situation Awareness</h3>
<p>An SA approach would manage complexity through a layered approach:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 39%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Routine Cases (Low Complexity):</th>
<th>Complex/Atypical Cases (Medium Complexity):</th>
<th>Emergent Situations (High Time Pressure):</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ul>
<li><p>Clean, simplified interface showing primary diagnosis suggestion</p></li>
<li><p>Key supporting evidence summarized</p></li>
<li><p>Basic confidence level displayed</p></li>
<li><p>Option to explore deeper if desired</p></li>
</ul></td>
<td><ul>
<li><p>More detailed presentation of AI reasoning</p></li>
<li><p>Explicit highlighting of uncertainty factors</p></li>
<li><p>Interactive elements allowing physicians to explore different diagnostic pathways</p></li>
<li><p>Comparison views of similar cases and their outcomes</p></li>
<li><p>Visual representation of how different factors influence the AI’s confidence</p></li>
</ul></td>
<td><ul>
<li><p>Streamlined interface focusing on critical information</p></li>
<li><p>Clear action recommendations</p></li>
<li><p>Quick access to essential data points</p></li>
<li><p>Minimized cognitive load</p></li>
</ul></td>
</tr>
</tbody>
</table>
<p>The system should adapt its complexity presentation based on factors like:</p>
<ul>
<li><p>Case urgency</p></li>
<li><p>Physician experience level</p></li>
<li><p>Time of day (cognitive load may be higher during night shifts)</p></li>
<li><p>Case similarity to typical presentations</p></li>
<li><p>Level of diagnostic certainty</p></li>
</ul>
<p>This framework recognizes that perceived complexity isn’t static - what seems straightforward at the start of a shift might feel overwhelming during a busy night. By structuring information presentation across these varying complexity levels, the system supports physicians’ natural diagnostic reasoning while maintaining their autonomy.</p>
<p>For example, in our appendicitis case:</p>
<ul>
<li><p>Initial presentation: Clean interface showing primary findings and straightforward recommendation</p></li>
<li><p>As atypical features emerge: System adapts to show more detailed reasoning and uncertainty factors</p></li>
<li><p>If emergency intervention needed: Interface shifts to highlight critical decision points and key actions</p></li>
<li><p>During detailed review: Allows exploration of full case complexity for learning purposes</p></li>
</ul>
<p>This SA-oriented approach helps physicians maintain situational awareness without being overwhelmed by the system’s inherent complexity, ultimately supporting better clinical decision-making while preserving physician autonomy and confidence.</p>
</section>
</section>
</section>
<section id="sec-takeaways" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Key Takeaways</h1>
<p>Medical AI integration requires careful attention to three key tensions:</p>
<ol type="1">
<li><p><strong>Automation and Human Agency</strong>: For AI to enhance rather than replace medical expertise, clinicians need appropriate visibility into AI systems. This means showing relevant information at the right time while preserving physician autonomy.</p></li>
<li><p><strong>System Uncertainty and User Confidence</strong>: AI systems must explicitly acknowledge their limitations and gaps in knowledge. Rather than presenting overconfident recommendations, they should support physician decision-making by clearly communicating uncertainties.</p></li>
<li><p><strong>System vs.&nbsp;Perceived Complexity</strong>: While medical AI systems are inherently complex, their interfaces must balance comprehensive information with usable design. The key is showing enough detail to maintain trust while preventing cognitive overload.</p></li>
</ol>
</section>
<section id="sec-conclusion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusion</h1>
<p>The successful integration of AI in medicine depends on understanding how humans and machines can work together effectively. By applying lessons from aviation and human-computer interaction, we can design AI systems that enhance rather than diminish medical expertise.</p>
<p>Situation awareness provides a valuable framework for addressing these challenges. When AI systems are designed to support clinician perception, comprehension, and projection, they can genuinely augment medical decision-making rather than attempting to replace clinical judgment.</p>
<p>The future of medical AI lies not in autonomous systems that work in isolation, but in thoughtfully designed tools that strengthen the doctor-patient relationship and improve clinical outcomes. As we continue developing these systems, maintaining this human-centered perspective will be crucial for realizing the full potential of AI in healthcare.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/dyadd\.github\.io\/Deepak_RJ");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Blog built with <a href="https://quarto.org/">Quarto</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dyadd/Deepak_RJ/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>© 2024 Deepak RJ</p>
</div>
  </div>
</footer>




</body></html>